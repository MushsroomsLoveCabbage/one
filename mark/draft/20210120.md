### Dubbo

![dubbo](https://upload-images.jianshu.io/upload_images/6302559-837be0fcd42a5765.png)

------

#### kafka
**参考文章**

[美团kafka改造]: https://tech.meituan.com/2021/01/14/kafka-ssd.html	"aaaa"


##### 问题

- I/O线程统一将请求中的数据写入到操作系统的PageCache后立即返回,当消息条数到达一定阈值后，Kafka应用本身或操作系统内核会触发强制刷盘操作。当存在consumer 实例消费慢，导致请求的数据已经落盘，会导致因缺页而依据LRU策略刷部分数据磁盘中，导致现有的主要线程消费的数据不在pagecache->往复导致吞吐降低

##### 处理方式

- FlashCache
- Kafka层改造
  - 增加SSD作为缓存
  - 依据数据消息偏移量，来减少非热点数据读刷到SSD。
  - 非缓存的数据直接从HDD中获取
  - LogSegment，后台线程定期把inactive的写到SSD

------

#### Trie树

```java
package com.zxy.dubbo.provider.design.limit;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * @author zxy
 * @version 1.0.0
 * @ClassName RateLimitTrie.java
 * @Description
 * @createTime 2021年01月28日 14:11:00
 */
public class RateLimitTrie {

    private TrieNode root;

    public RateLimitTrie() {
        this.root = new TrieNode("");
    }

    public void addNode(String key){
        addNode(key, "/");
    }

    public void addNode(String key, String splitKey){
        String[] values = key.split(splitKey);
        root.add(values, 1);
    }

    public boolean isMatch(String key){
        return isMatch(key, "/");
    }

    public boolean isMatch(String value, String splitKey){
        String[] values = value.split(splitKey);
        return root.isMatch(values, 1);
    }

    class TrieNode{

        String key;

        Map<String, TrieNode> subMap;

        public TrieNode(String key) {
            this.key = key;
            this.subMap = new ConcurrentHashMap<>();
        }

        public TrieNode(String key, Map<String, TrieNode> subMap) {
            this.key = key;
            this.subMap = subMap;
        }

        public boolean isMatch(String[] values, int index){
            if(index >= values.length){
                if(subMap.isEmpty()){
                    return true;
                }
                return false;
            }
            String temp = values[index];
            if("*".equals(temp)){
                if(subMap.isEmpty()){
                    return true;
                }

                for(TrieNode single : subMap.values()){
                    if(single.isMatch(values,index+1)){
                        return true;
                    }
                }

            }
            if("**".equals(temp)){
                //** 是最后的则统配成功
                if(index == values.length - 1){
                    return true;
                }
                //** 不是最后，但是树无子节点，统配失败
                if(subMap.isEmpty()){
                    return false;
                }

                //子节点统配下个字符或者子节点统配**
                for(TrieNode single : subMap.values()){
                    if(single.isMatch(values, index + 1) || single.isMatch(values, index)){
                        return true;
                    }
                }

            }
            if(subMap.containsKey(temp)){
                return subMap.get(temp).isMatch(values, index+1);
            }
            return false;
        }

        public void add(String[] values, int index){
            if(index >= values.length){
                return;
            }
            String temp = values[index];
            TrieNode trieNode = null;
            if(subMap.containsKey(temp)){
                trieNode = subMap.get(temp);
            } else {
                trieNode = new TrieNode(temp);
                subMap.put(temp, trieNode);
            }
            trieNode.add(values, index+1);
        }
    }
}

```



