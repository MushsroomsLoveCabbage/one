### 消息中间件

------

| 特性                     | ActiveMQ                              | RabbitMQ                                           | RocketMQ                                                     | Kafka                                                        |
| ------------------------ | ------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量               | 万级，比 RocketMQ、Kafka 低一个数量级 | 同 ActiveMQ                                        | 10 万级，支撑高吞吐                                          | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响 |                                       |                                                    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                   | ms 级                                 | 微秒级，这是 RabbitMQ 的一大特点，延迟最低         | ms 级                                                        | 延迟在 ms 级以内                                             |
| 可用性                   | 高，基于主从架构实现高可用            | 同 ActiveMQ                                        | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性               | 有较低的概率丢失数据                  | 基本不丢                                           | 经过参数优化配置，可以做到 0 丢失                            | 同 RocketMQ                                                  |
| 功能支持                 | MQ 领域的功能极其完备                 | 基于 erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好                      | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |

#### 消息数据丢失

##### 生产端

* 投递的消息未设置ACK,消息因为网络原因，导致数据丢失。(开启ACK)

* 消息送达（已被ACK）但未刷盘，系统宕机导致消息丢失。
* 集群状态，消息只被Master确认，未被所有服务确定。主挂，消息丢失。（主从ACK）
* 对于投递的消息的回执ACK处理，如果是刷盘ACK，那需要在生产端增加一个任务，监控所有投递但未ACK的消息。然后在消息未投递成功落盘时重发。

##### 消费端

* 消息自动提交offset, 位移提交了，但数据操作还未提交完，服务宕机了。（手动提交offset）

##### 消息顺序性

* 消费端在开启多线程消费时候，需要注意将消息队列按key分配到不同队列，然后由多线程去消费

------

#### 线上系统宕机，导致消息积压如何处理

* 修复问题，然后停掉现有Consumer,
* 新建Topic ,增加分区等方式，消费消息
* 临时增加多个Consumer ，消费新建的Topic，临时处理
* 处理完之后恢复原有的架构

